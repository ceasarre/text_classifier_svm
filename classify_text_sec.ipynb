{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text representation byWord Embeddings Transformers -> Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 15:33:43.248708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-06 15:33:43.248734: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-06 15:33:43.248758: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dac-Latitude-E7450): /proc/driver/nvidia/version does not exist\n",
      "2022-01-06 15:33:43.248941: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import preprocessor as p\n",
    "from spacy.lang.en import stop_words as spacy_stopwords  # we use spacy's list of stop words to clean our data\n",
    "\n",
    "stop_words = spacy_stopwords.STOP_WORDS\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    text = re.sub(r'\\W+', ' ', text)  # remove non-alphanumeric characters\n",
    "    # replace numbers with the word 'number'\n",
    "    text = re.sub(r\"\\d+\", \"number\", text)\n",
    "    # don't consider sentenced with less than 3 words (i.e. assumed noise)\n",
    "    if len(text.strip().split()) < 3:\n",
    "        return None\n",
    "    text = text.lower()  # lower case everything\n",
    "    \n",
    "    return text.strip() # remove redundant spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: sci.electronics\n",
      "From: xandor@unixg.ubc.ca (John Gilbert )\n",
      "Subject: Re: Exploding TV!\n",
      "Organization: The University of British Columbia\n",
      "Lines: 4\n",
      "Distribution: usa\n",
      "NNTP-Posting-Host: unixg.ubc.ca\n",
      "\n",
      " Just as a not of possible interest on this subject ..\n",
      "It is my understanding that exploding televisions were a major cause of\n",
      "domestic accidents in the Soviet Union in past years!\n",
      "  \n",
      "\n",
      "from xandor unixg ubc ca john gilbert subject re exploding tv organization the university of british columbia lines number distribution usa nntp posting host unixg ubc ca just as a not of possible interest on this subject it is my understanding that exploding televisions were a major cause of domestic accidents in the soviet union in past years\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Prepare data\n",
    "\n",
    "corpus = fetch_20newsgroups()\n",
    "categories = fetch_20newsgroups()[\"target_names\"]\n",
    "train_set = fetch_20newsgroups(subset = 'train', categories = categories)\n",
    "test_set = fetch_20newsgroups(subset = 'test', categories = categories)\n",
    "\n",
    "X_train = train_set.data\n",
    "y_train = train_set.target\n",
    "\n",
    "X_test = test_set.data\n",
    "y_test = test_set.target\n",
    "\n",
    "\n",
    "sample = 32\n",
    "\n",
    "# show sample of train_set\n",
    "print(\"LABEL: {}\".format(categories[y_train[sample]]))\n",
    "print(X_train[sample])\n",
    "print(clean(X_train[sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44263/3351720209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mfind_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_44263/3351720209.py\u001b[0m in \u001b[0;36mfind_header\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpattern2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'^From'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfind_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# find th header\n",
    "sample = 36\n",
    "# print(X_train[sample])\n",
    "\n",
    "def find_header(text):\n",
    "    pattern = re.compile(r'(^F)(.|\\n)*(\\d$)')\n",
    "    pattern3 = re.compile(r'(^F)(.|\\n)*(Lines)(.)*(\\d$)')\n",
    "    pattern2 = re.compile(r'^From')\n",
    "    mo = pattern3.search(text)\n",
    "    print(mo.group())\n",
    "\n",
    "find_header(X_train[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nbshare.io/notebook/197284676/Word-Embeddings-Transformers-In-SVM-Classifier-Using-Python/ -> clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1622ea77d34425ecad25b4a1cbdcb70f1221a863c9dbfcb7c669136b365448b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('studia': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
