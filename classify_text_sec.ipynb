{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 16:18:36.318442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-07 16:18:36.318484: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "from clean_text import clean_text\n",
    "\n",
    "import string\n",
    "import re\n",
    "import preprocessor as p\n",
    "from spacy.lang.en import stop_words as spacy_stopwords  # we use spacy's list of stop words to clean our data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text representation byWord Embeddings Transformers -> Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: rec.sport.hockey\n",
      "From: dchhabra@stpl.ists.ca (Deepak Chhabra)\n",
      "Subject: Re: Goalie masks\n",
      "Nntp-Posting-Host: stpl.ists.ca\n",
      "Organization: Solar Terresterial Physics Laboratory, ISTS\n",
      "Lines: 21\n",
      "\n",
      "In article <120666@netnews.upenn.edu> kkeller@mail.sas.upenn.edu (Keith Keller) writes:\n",
      ">My vote goes to John Vanbiesbrouck.  His mask has a skyline of New York\n",
      ">City, and on the sides there are a bunch of bees (Beezer).  It looks\n",
      ">really sharp.\n",
      "\n",
      "Funny you should mention this; one time on HNIC Don Cherry pointed out\n",
      "Vanbiesbrouck's mask.  He _hated_ it.  I think he said something to the effect\n",
      "of:\n",
      "\"You see?  He was great last year; now he goes out and gets that dopey mask \n",
      "and he can't stop a beachball!\"\n",
      "\n",
      "You may or may not take Cherry seriously at all, but I cracked up when I heard\n",
      "it.\n",
      "\n",
      "I think Ed Belfour has the current best mask in the NHL btw.  I also like\n",
      "Moog's, and I'll give Fuhr's new one an honourable mention, although I haven't\n",
      "seen it closely yet (it looked good from a distance!).  What's also neat is\n",
      "Chevaldae's in Detroit; they call him \"Chevy\" so he has two checkered flags\n",
      "painted at the top as in an auto race.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Prepare data\n",
    "\n",
    "corpus = fetch_20newsgroups()\n",
    "categories = fetch_20newsgroups()[\"target_names\"]\n",
    "train_set = fetch_20newsgroups(subset = 'train', categories = categories)\n",
    "test_set = fetch_20newsgroups(subset = 'test', categories = categories)\n",
    "\n",
    "X_train = train_set.data\n",
    "y_train = train_set.target\n",
    "\n",
    "X_test = test_set.data\n",
    "y_test = test_set.target\n",
    "\n",
    "\n",
    "sample = 35\n",
    "\n",
    "# show sample of train_set\n",
    "print(\"LABEL: {}\".format(categories[y_train[sample]]))\n",
    "print(X_train[sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: rec.sport.hockey\n",
      "from dchhabra stpl ists ca deepak chhabra subject re goalie masks nntp posting host stpl ists ca organization solar terresterial physics laboratory ists lines number in article number netnews upenn edu kkeller mail sas upenn edu keith keller writes my vote goes to john vanbiesbrouck his mask has a skyline of new york city and on the sides there are a bunch of bees beezer it looks really sharp funny you should mention this one time on hnic don cherry pointed out vanbiesbrouck s mask he _hated_ it i think he said something to the effect of you see he was great last year now he goes out and gets that dopey mask and he can t stop a beachball you may or may not take cherry seriously at all but i cracked up when i heard it i think ed belfour has the current best mask in the nhl btw i also like moog s and i ll give fuhr s new one an honourable mention although i haven t seen it closely yet it looked good from a distance what s also neat is chevaldae s in detroit they call him chevy so he has two checkered flags painted at the top as in an auto race\n"
     ]
    }
   ],
   "source": [
    "# Show the text cleaner work\n",
    "cleaned = clean_text(X_train[sample])\n",
    "\n",
    "print(\"LABEL: {}\".format(categories[y_train[sample]]))\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nbshare.io/notebook/197284676/Word-Embeddings-Transformers-In-SVM-Classifier-Using-Python/ -> clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean X_train and X_test\n",
    "X_train = [clean_text(x_train) for x_train in X_train]\n",
    "X_test = [clean_text(x_test) for x_test in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data instances before transform 7532\n"
     ]
    }
   ],
   "source": [
    "# we just feed in the list of sentences, and we get the vector representation of each sentence\n",
    "# we don't have enough memory to apply embeddings in one shot,\n",
    "# so we have to split the data into batches and concatenate them later\n",
    "\n",
    "def transform_data(data, split):\n",
    "    splits = np.array_split(data, split)\n",
    "    l = list()\n",
    "    for split in splits:\n",
    "        l.append(embed(split))\n",
    "    data = tensorflow.concat(l, axis=0)\n",
    "    del l\n",
    "\n",
    "    return data\n",
    "\n",
    "# Do not have enough memory\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print(f'Data instances before transform {len(X_test)}')\n",
    "\n",
    "X_test = transform_data(X_test, 1)\n",
    "print(f'Data instances after transform {len(X_test)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI SIE CRASHUJE SSYTEM NA CPU, NAWET JAK PROBUJE PRZEKSZTAŁCIĆ JEDNĄ DANĄ NA RAZ XD, spróbuj to puścić. Jak się uda to trzeba tu niżej te wszystkie klasyfikatory jak w pliku `classify_text_first.ipynb` przelecieć i sprawdzić, poniżej wrzucam kod jak to mnie wiecej bedzie wyglądać i porobić wykresy i macierze pomyłek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = SVC() # z parametrami\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(np.array(X_test))\n",
    "\n",
    "# I wykresy porobić oraz metryki jak w poprzednim pliku "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1622ea77d34425ecad25b4a1cbdcb70f1221a863c9dbfcb7c669136b365448b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('studia': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
